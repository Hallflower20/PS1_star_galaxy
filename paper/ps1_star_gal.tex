%%
%% Beginning of file 'sample61.tex'
%%
%% Modified 2016 September
%%
%% This is a sample manuscript marked up using the
%% AASTeX v6.1 LaTeX 2e macros.
%%
%% AASTeX is now based on Alexey Vikhlinin's emulateapj.cls 
%% (Copyright 2000-2015).  See the classfile for details.

%% AASTeX requires revtex4-1.cls (http://publish.aps.org/revtex4/) and
%% other external packages (latexsym, graphicx, amssymb, longtable, and epsf).
%% All of these external packages should already be present in the modern TeX 
%% distributions.  If not they can also be obtained at www.ctan.org.

%% The first piece of markup in an AASTeX v6.x document is the \documentclass
%% command. LaTeX will ignore any data that comes before this command. The 
%% documentclass can take an optional argument to modify the output style.
%% The command below calls the preprint style  which will produce a tightly 
%% typeset, one-column, single-spaced document.  It is the default and thus
%% does not need to be explicitly stated.
%%
%%
%% using aastex version 6.1
\documentclass[twocolumn]{aastex62}

%% The default is a single spaced, 10 point font, single spaced article.
%% There are 5 other style options available via an optional argument. They
%% can be envoked like this:
%%
%% \documentclass[argument]{aastex61}
%% 
%% where the arguement options are:
%%
%%  twocolumn   : two text columns, 10 point font, single spaced article.
%%                This is the most compact and represent the final published
%%                derived PDF copy of the accepted manuscript from the publisher
%%  manuscript  : one text column, 12 point font, double spaced article.
%%  preprint    : one text column, 12 point font, single spaced article.  
%%  preprint2   : two text columns, 12 point font, single spaced article.
%%  modern      : a stylish, single text column, 12 point font, article with
%% 		  wider left and right margins. This uses the Daniel
%% 		  Foreman-Mackey and David Hogg design.
%%
%% Note that you can submit to the AAS Journals in any of these 6 styles.
%%
%% There are other optional arguments one can envoke to allow other stylistic
%% actions. The available options are:
%%
%%  astrosymb    : Loads Astrosymb font and define \astrocommands. 
%%  tighten      : Makes baselineskip slightly smaller, only works with 
%%                 the twocolumn substyle.
%%  times        : uses times font instead of the default
%%  linenumbers  : turn on lineno package.
%%  trackchanges : required to see the revision mark up and print its output
%%  longauthor   : Do not use the more compressed footnote style (default) for 
%%                 the author/collaboration/affiliations. Instead print all
%%                 affiliation information after each name. Creates a much
%%                 long author list but may be desirable for short author papers
%%
%% these can be used in any combination, e.g.
%%
%% \documentclass[twocolumn,linenumbers,trackchanges]{aastex61}

%% AASTeX v6.* now includes \hyperref support. While we have built in specific
%% defaults into the classfile you can manually override them with the
%% \hypersetup command. For example,
%%
%%\hypersetup{linkcolor=red,citecolor=green,filecolor=cyan,urlcolor=magenta}
%%
%% will change the color of the internal links to red, the links to the
%% bibliography to green, the file links to cyan, and the external links to
%% magenta. Additional information on \hyperref options can be found here:
%% https://www.tug.org/applications/hyperref/manual.html#x1-40003

%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
\usepackage{multirow, amsmath}
\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand{\sm}{M_\odot}
\newcommand{\sr}{R_\odot}

%% Reintroduced the \received and \accepted commands from AASTeX v5.2
\received{\today}
\revised{}
\accepted{}
%% Command to document which AAS Journal the manuscript was submitted to.
%% Adds "Submitted to " the arguement.
\submitjournal{PASP}

%% Mark up commands to limit the number of authors on the front page.
%% Note that in AASTeX v6.1 a \collaboration call (see below) counts as
%% an author in this case.
%
%\AuthorCollaborationLimit=3
%
%% Will only show Schwarz, Muench and "the AAS Journals Data Scientist 
%% collaboration" on the front page of this example manuscript.
%%
%% Note that all of the author will be shown in the published article.
%% This feature is meant to be used prior to acceptance to make the
%% front end of a long author article more manageable. Please do not use
%% this functionality for manuscripts with less than 20 authors. Conversely,
%% please do use this when the number of authors exceeds 40.
%%
%% Use \allauthors at the manuscript end to show the full author list.
%% This command should only be used with \AuthorCollaborationLimit is used.

%% The following command can be used to set the latex table counters.  It
%% is needed in this document because it uses a mix of latex tabular and
%% AASTeX deluxetables.  In general it should not be needed.
%\setcounter{table}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section outlines numerous optional output that
%% can be displayed in the front matter or as running meta-data.
%%
%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
\shorttitle{PS1 Star-galaxy Catalog}
\shortauthors{One then the other}
%%
%% You can add a light gray and diagonal water-mark to the first page 
%% with this command:
\watermark{DRAFT}
%% where "text", e.g. DRAFT, is the text to appear.  If the text is 
%% long you can control the water-mark size with:
%  \setwatermarkfontsize{dimension}
%% where dimension is any recognized LaTeX dimension, e.g. pt, in, etc.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section defines new commands for comments from co-authors
%%
\newcommand{\yutaro}[1]{{\color{red} yt: {#1}}}
\newcommand{\NC}[1]{{\color{brown} NC: {#1}}}
\newcommand{\aam}[1]{{\color{blue} aam: {#1}}}
\newcommand{\todo}[1]{{\color{magenta} to-do: {#1}}}
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is the end of the preamble.  Indicate the beginning of the
%% manuscript itself with \begin{document}.

\begin{document}

\title{\textbf{something better needed} A Machine Learning Model to Separate Stars and Galaxies in PanSTARRS1 Data}

%% LaTeX will automatically break titles if they run longer than
%% one line. However, you may use \\ to force a line break if
%% you desire. In v6.1 you can include a footnote in the title.

%% A significant change from earlier AASTEX versions is in the structure for 
%% calling author and affilations. The change was necessary to implement 
%% autoindexing of affilations which prior was a manual process that could 
%% easily be tedious in large author manuscripts.
%%
%% The \author command is the same as before except it now takes an optional
%% arguement which is the 16 digit ORCID. The syntax is:
%% \author[xxxx-xxxx-xxxx-xxxx]{Author Name}
%%
%% This will hyperlink the author name to the author's ORCID page. Note that
%% during compilation, LaTeX will do some limited checking of the format of
%% the ID to make sure it is valid.
%%
%% Use \affiliation for affiliation information. The old \affil is now aliased
%% to \affiliation. AASTeX v6.1 will automatically index these in the header.
%% When a duplicate is found its index will be the same as its previous entry.
%%
%% Note that \altaffilmark and \altaffiltext have been removed and thus 
%% can not be used to document secondary affiliations. If they are used latex
%% will issue a specific error message and quit. Please use multiple 
%% \affiliation calls for to document more than one affiliation.
%%
%% The new \altaffiliation can be used to indicate some secondary information
%% such as fellowships. This command produces a non-numeric footnote that is
%% set away from the numeric \affiliation footnotes.  NOTE that if an
%% \altaffiliation command is used it must come BEFORE the \affiliation call,
%% right after the \author command, in order to place the footnotes in
%% the proper location.
%%
%% Use \email to set provide email addresses. Each \email will appear on its
%% own line so you can put multiple email address in one \email call. A new
%% \correspondingauthor command is available in V6.1 to identify the
%% corresponding author of the manuscript. It is the author's responsibility
%% to make sure this name is also in the author list.
%%
%% While authors can be grouped inside the same \author and \affiliation
%% commands it is better to have a single author for each. This allows for
%% one to exploit all the new benefits and should make book-keeping easier.
%%
%% If done correctly the peer review system will be able to
%% automatically put the author and affiliation information from the manuscript
%% and save the corresponding author the trouble of entering it by hand.

\correspondingauthor{A.~A.~Miller}
\email{amiller@northestern.edu}

% \author[0000-0001-9515-478X]{A.~A.~Miller}
% \affil{Center for Interdisciplinary Exploration and Research in Astrophysics (CIERA) and Department of Physics and Astronomy, Northwestern University, 2145 Sheridan Road, Evanston, IL 60208, USA}
% \affil{The Adler Planetarium, Chicago, IL 60605, USA}

\author{Concerned ZTF Scientists}
\affil{Zwicky Transient Facility}

%% Note that the \and command from previous versions of AASTeX is now
%% depreciated in this version as it is no longer necessary. AASTeX 
%% automatically takes care of all commas and "and"s between authors names.

%% AASTeX 6.1 has the new \collaboration and \nocollaboration commands to
%% provide the collaboration status of a group of authors. These commands 
%% can be used either before or after the list of corresponding authors. The
%% argument for \collaboration is the collaboration identifier. Authors are
%% encouraged to surround collaboration identifiers with ()s. The 
%% \nocollaboration command takes no argument and exists to indicate that
%% the nearby authors are not part of surrounding collaborations.

%% Mark off the abstract in the ``abstract'' environment. 
\begin{abstract}

We did a decent job of separating stars and galaxies.

\end{abstract}

%% Keywords should appear after the \end{abstract} command. 
%% See the online documentation for the full list of available subject
%% keywords and the rules for their use.
\keywords{catalogs --- galaxies: statistics --- methods: data analysis --- methods: statistical --- stars: statistics --- surveys}

%% From the front matter, we move on to the body of the paper.
%% Sections are demarcated by \section and \subsection, respectively.
%% Observe the use of the LaTeX \label
%% command after the \subsection to give a symbolic KEY to the
%% subsection for cross-referencing in a \ref command.
%% You can use LaTeX's \ref and \label commands to keep track of
%% cross-references to sections, equations, tables, and figures.
%% That way, if you change the order of any elements, LaTeX will
%% automatically renumber them.

%% We recommend that authors also use the natbib \citep
%% and \citet commands to identify citations.  The citations are
%% tied to the reference list via symbolic KEYs. The KEY corresponds
%% to the KEY in the \bibitem in the reference list below. 

\section{Introduction}\label{sec:intro}

\yutaro{I've restructured the intro, I think we should pitch the paper as PS1
catalog used by ZTF, rather than ZTF project. That way other people will
hopefully use the catalog even if they do not use ZTF.}

The proliferation of wide-field optical detectors has led to a plethora of
imaging catalogs in the past two decades. \yutaro{I think we should add some
general text here about the importance of separating stars and galaxies here
- do you want to take the first effort for that?}

Given the many applications for a catalog that separates point sources from
galaxies, we turn our attention to the wide-field Pan-STARRS1 (PS1) survey
\citep{Chambers16}, whose 3$\pi$ survey provides a felicitous data set.

The 1.8\,m PS1 telescope is equipped with a wide-field ($\sim$7\,deg$^2$) 1.4
gigapixel camera and is located at Haleakala Observatory in Hawaii
\citep{Hodapp04}. PS1 primarily uses five broadband filters,
$g_{\mathrm{P1}}$, $r_{\mathrm{P1}}$, $i_{\mathrm{P1}}$, $z_{\mathrm{P1}}$,
and $y_{\mathrm{P1}}$ (hereafter $grizy_{\mathrm{P1}}$). The PS1 3$\pi$
survey scanned the entire visible sky ($\mathrm{Dec.}>-30^\circ$) 60 times in
the five filters over a four-year time span \citep{Chambers16}. This repeated
imaging was used to create deep stacks \citep{Magnier16b}, with a typical
5$\sigma$ depth of $\sim$23.2\,mag with a median seeing of $1.19\arcsec$ in
the $r$-band \citep{Tonry12, Schlafly12, Chambers16}. The first PS1 data
release (DR1) provides flux and pixel-based shape measurements for $>$3
billion sources \citep{Flewelling16}.

Our aim is to develop a large, deep catalog of stars (point sources) and
galaxies using PS1 data. The catalog is to be general purpose, however, our
immediate goal is to support the real-time search for transients in the
Zwicky Transient Facility (ZTF; \citealt{Bellm18}). Previously, a similar
catalog was developed using Palomar Transient Factory (PTF) data
\citep{Miller17}. 

The PTF star--galaxy catalog was developed using \texttt{SExtractor}
\citep{bertin96} flux and shape measurements made on deep stacks of PTF
imaging. Stars and galaxies were separated using a machine learning
methodology utilizing the random forest (RF) algorithm \citep{Breiman01}.
Briefly, supervised machine learning methods build a non-parametric mapping
between \textit{features}, measured properties, and \textit{labels}, the
target classification, via a training set. The training set contains sources
for which the labels are already known, facilitating the construction of a
features to labels mapping. Following this training, the machine learning
model can produce predictions on new observations where the labels are
unknown.

The PTF point-source catalog was constructed to support the real-time search
for electromagetic counterparts to gravitational wave events. Given that
these events are expected to be very rare (\todo{citation}), the figure of
merit (FoM) for the PTF model was defined as the true positive rate
(corresponding to the fraction of stars that are correctly classified) at a
fixed false positive rate (fraction of galaxies that are misclassified) equal
to 0.005 \citep{Miller17}. While the PTF point-source catalog includes
$\sim$1.7$\times 10^8$ objects, it is expected that a full
$\sim$8$\times10^7$ point sources are excluded as false negatives
\citep{Miller17}.

A star--galaxy separation model built on PS1 data will produce dramatic
improvements over the PTF catalog. PS1 observations are deeper, feature
better seeing, and include 5 filters (the PTF catalog was built with
observations in a single filter, $R_\mathrm{PTF}$). Additionally, one of the
12 CCDs in the PTF camera did not work \citep{Law09}, meaning $\sim$8\% of
the sky above $\mathrm{Dec.} = 30^\circ$ has no classifications in the PTF
catalog.

Here, we construct a new star--galaxy separation model using PS1 DR1 data in
conjunction with a new machine learning methodology. The model is trained
using \textit{Hubble Space Telescope} observations, which should provide an
improvement over the Sloan Digital Sky Survey (SDSS; \citealt{York00})
spectroscopic training set used in \citet{Miller17}. As in \citet{Miller17},
we use the RF algorithm to separate point sources and extended sources. Our
new PS1 model outperforms alternatives and has already been incorporated into
the ZTF real-time pipeline.

\todo{Need to add something about optimizing the same FoM as the first Miller paper}

%%%
\if0
The system comprises a 1.8 m primary and 0.9 m secondary mirrors \citep{Hodapp04}, 
produces a field of view of 3.3 deg$^2$ with 60 CCD chips each of 4800$\times$4800 pixels, 
and the pixel resolution is 0.258 arcsec pixel$^{-1}$ at the focal plane. 
The filter system consists of five main broadband filters, 
$g_{\mathrm{P1}}$, $r_{\mathrm{P1}}$, $i_{\mathrm{P1}}$, $z_{\mathrm{P1}}$, and $y_{\mathrm{P1}}$, 
and that effective wavelength is 481 nm, 617 nm, 752 nm, 866 nm, and 962 nm, 
respectively \citep{Tonry12, Schlafly12}. 
The typical 5$\sigma$ depth of stack image is 23.3, 23.2, 23.1, 22.3, and 21.3 mag 
white that of a single epoch is 22.0, 21.8, 21.5, 20.9, and 19.7 mag in the AB system, 
with a median seeing of 1.31, 1.19, 1.11, 1.07, and 1.02 arcsec, respectively \citep{Chambers16}. 
\fi
%%%


\section{Model Data}\label{sec:model_data}

Data for the star-galaxy model were obtained from the PS1 casjobs
server.\footnote{\url{http://mastweb.stsci.edu/ps1casjobs/home.aspx}} The PS1
database provides flux measurements via aperture photometry,
point-spread-function (PSF) photometry, and \citet{Kron80}
photometry.\footnote{A subset of bright sources ($i < 21\,\mathrm{mag}$)
outside the Galactic plane have additional photometric measurements, e.g.,
exponential or \citet{Sersic63} profiles, in the \textit{StackModelFitExp} and
\textit{StackModelFitSer} tables, respectively. We ignore these measurements
for this study as they are not available for all sources.} These flux
measurements are produced by PS1 in 3 different ways. The mean brightness
measured on the individual PS1 frames is reported in the \textit{MeanObject}
table, the mean brightness measured via forced-PSF/aperture photometry on the
individual PS1 frames is reported in the \textit{ForcedMeanObject} table, and
finally, the brightness measured on the full-depth stacked PS1 images is
reported in the \textit{StackObjectThin} table. The
\textit{StackObjectAttributes} table further supplements these tables with
point-source object shape measurements, which prove useful to discriminate
stars and galaxies. Ultimately, see \S\ref{sec:simple_model}, we use flux
measurements from the \textit{StackObjectThin} table and shape measurements
from the \textit{StackObjectAttributes} to build our models.

\subsection{The \textit{HST} Training Set} \label{sec:hst_train}

A fundamental challenge in the construction of any supervised machine learning
model is the curation of a high-fidelity training set. A subset of the data
that requires classification must have known labels so the machine can learn
the proper mapping between features and labels. The superior image quality of
the \textit{Hubble Space Telescope} (\textit{HST}) provides exceptionally
accurate morphological classifications, making it an ideal source of a training
set for lower quality ground-based imaging (e.g., \citealt{Lupton01}). The
downside of \textit{HST} is that the field of view is relatively small, so it
is difficult to construct a large and diverse training set suitable for
predictions over the entire sky.

We use the largest contiguous area imaged by \textit{HST}, the 1.64\,deg$^2$
COSMOS field, to construct a training set for our models. Morphological
classifications of \textit{HST} COSMOS sources are provided in
\citet{Leauthaud07}. \citeauthor{Leauthaud07} demonstrate reliable
classifications to $\sim$25\,mag, which is significantly deeper than the
faintest sources detected by PS1. We identify counterparts in the PS1 and
\textit{HST} data by performing a spatial crossmatch between the two catalogs
using a 1\arcsec radius.\footnote{This matching radius is the same employed
by PS1 to associate individual detections in the \textit{MeanObject} table
with detections in the \textit{StackObjectAttributes} table.} We further
excluded sources from the \citet{Leauthaud07} catalog with
$\texttt{MAG\_AUTO} > 25$\,mag, as these sources are too faint to be detected
by PS1 meaning their crossmatch counterparts are likely spurious. Following
this procedure, we find that there are 87,431 sources in the
\citet{Leauthaud07} catalog with PS1 counterparts. Of these, 80,974 are
unique in that there is a one-to-one correspondence between \textit{HST}
source and a single PS1 \textit{ObjID}. The training set is further reduced
to 75,927 once our detection criteria are applied (see
\S\ref{sec:simple_model}), and, of those, only 47,093 have
$\texttt{nDetections} \ge 1$ in the PS1 database (hereafter, the \textit{HST}
training set).\footnote{$\texttt{nDetections}$ refers to the number of
detections in individual PS1 exposures. Thus, \textit{StackObjectThin} souces
can have $\texttt{nDetections}$ = 0 if they are only detected in the PS1
stack images.}

\subsection{The SDSS Training Set}\label{sec:sdss}

\begin{figure*}[htb]
 \centering
  \includegraphics[width=7.2in]{./Figures/ColorMagDiagramComb.pdf}
  \caption{
  PS1 color-magnitude diagrams for \textit{left}: $10^6$ randomly selected sources, \textit{center}: the \textit{HST} training set, and \textit{right}: the SDSS training set. The primary panels show a two-dimensional (2D) Gaussian kernel density estimate (KDE) of the probability density function (PDF) of each subset of sources in the $r_\mathrm{PS1}$--$g_\mathrm{PS1} - r_\mathrm{PS1}$ plane. The shown contour levels extend from 0.9 to 0.1 in 0.1 intervals. To the top and right of the primary panels are marginalized 1D KDEs of the PDF for the $g_\mathrm{PS1} - r_\mathrm{PS1}$ color and $r_\mathrm{PS1}$ brightness, respectively. Kron aperture measurements from the \textit{StackObjectThin} table are used to estimate each of the PDFs. \yutaro{Is this last sentence correct? Also - I think we should use some color here to break the monotony of the black text on a white background}
  }
  %
  \label{fig:cmd}
\end{figure*}

The SDSS spectroscopic catalog classifies everything it observes as either a
star, galaxy, or quasi-stellar object (QSO). Using a $1\arcsec$ cross-match
radius, we find 3,822,297 sources with SDSS optical spectra have PS1
counterparts (hereafter, the SDSS training set). Thus, with an orders of
magnitude larger training set, and spectroscopic classifications that should
be pristine and superior to mophological clsasifications, one might expect
the SDSS training set to be optimal for training the machine learning model.
However, as noted in \citep{Miller17}, the SDSS spectroscopic targeting
algorithms were highly biased, and as a result prove challenging as a
training set.

Color-magnitude diagrams (CMDs) of the \textit{HST} and SDSS training sets
are compared to a random selection of $10^6$ sources from the PS1 database in
Figure~\ref{fig:cmd}. It is clear from Figure~\ref{fig:cmd} that the SDSS
training set is completely different from typical sources in PS1 and that
there are few SDSS sources in the highest density regions of the PS1 CMD.
Given the stark mismatch between typical PS1 sources and the SDSS training
set, we adopt the \textit{HST} training set for the development of our model.
We retain the SDSS training set as an independent test set to assess the
accuracy of the model following construction.

\section{Model Features}\label{sec:model_features}

In addition to developing a training set, we must select features to use as an input for the model. As noted in \S\ref{sec:model_data}, the PS1 database provides flux and shape measurements in each of the $grizy_\mathrm{PS1}$ filters. Adopting each of these measurements as features for the model presents a significant problem: missing data. There are relatively few sources in the PS1 database that are detected in all 5 filters. Typically, to cope with missing data one can either (i) remove sources detected in fewer than 5 filters, or (ii) assign some value, via either imputation (e.g., \citealt{Miller17}) or the use of a dummy variable, to the missing data. Given that the vast majority of PS1 sources are faint and are not detected in all 5 filters, neither of these possiblities is attractive for our present purposes.

Rather than use the raw features from the database, we engineer a series of ``white flux'' features that combine the relevant measurements across all filters in which a source is detected. In a given filter, a source is detected if the $\mathtt{PSFFlux}_f$, $\mathtt{KronFlux}_f$, and $\mathtt{ApFlux}_f$ are \textit{all $> 0$}, where the $f$ subscript refers to a specific filter. The ``white flux'' feature is then created as:
%
\begin{equation}
    \mathtt{white[Feat]} =  \frac{\sum_f^{f = grizy_\mathrm{PS1}} w_f  \, \mathtt{Feat}_f \, \mathrm{det}_f}{\sum_f^{f = grizy_\mathrm{PS1}} w_f}, 
\end{equation}
%
where the sum is over the 5 PS1 filters, \texttt{Feat} is the feature from the \textit{StackObjectAttributes} table, $\mathrm{det}_f = 1$ if the source is detected in the $f$ filter, as defined above, or $\mathrm{det}_f = 0$ if not detected, and $w_f$ is the weight assigned to each filter:
%
\begin{equation}
    w_f = \left(\frac{\mathtt{KronFlux}_f}{\mathtt{KronFluxErr}_f}\right)^2,
\end{equation}
%
equivalent to signal-to-noise ratio (SNR) squared in the given filter. Ultimately, the ``white flux'' features correspond to a weighted mean, with weights equal to the square of the SNR. 

Our final model includes 11 ``white flux'' features to separate stars and
galaxies. The database features include: \texttt{PSFFlux},\footnote{For the
\texttt{PSFFlux} feature $w_f =
(\mathtt{PSFFlux}_f/\mathtt{PSFFluxErr}_f)^2$.} \texttt{KronFlux},
\texttt{ApFlux},\footnote{For the \texttt{ApFlux} feature $w_f =
(\mathtt{ApFlux}_f/\mathtt{ApFluxErr}_f)^2$.} \texttt{ExtNSigma},
\texttt{KronRad}, \texttt{psfChiSq}, \texttt{psfLikelihood},
\texttt{momentYY}, \texttt{momentXY}, \texttt{momentXX}, and
\texttt{momentRH}.\footnote{Prior to their ``white flux'' calculation the
shape features (\texttt{KronRad}, \texttt{momentYY}, \texttt{momentXY},
\texttt{momentXX}, and \texttt{momentRH}) are normalized by the seeing in the
respective bandpass, which we define as the \texttt{psfMajorFWHM} and
\texttt{psfMinorFWHM} added in quadrature. \texttt{KronRad} has units of
arcsec, \texttt{momentRH} has units of arcsec$^{0.5}$, and the remaining
shape features have units of arcsec$^{2}$. They are each normalized by
dividing by the seeing raised to the appropriate power. } The remaining
features in the database were either uninformative or would bias the model,
such as R.A.\ and Dec.\ (see e.g., \citealt{Richards12a}). We do not directly
include \texttt{whitePSFFlux}, \texttt{whiteKronFlux}, and
\texttt{whiteApFlux} in the model. We found that the inclusion of these
features resulted in a bias whereby all sources brighter than $\sim$16\,mag
were automatically classified as stars. Instead, we include the ratio of the
different flux measures: \texttt{whitePSFKronRatio} =
\texttt{whitePSFFlux}/\texttt{whiteKronFlux}, \texttt{whitePSFApRatio} =
\texttt{whitePSFFlux}/\texttt{whiteApFlux}, as well as a third feature
\texttt{whitePSFKronDist} (see \S\ref{sec:simple_model}).

As we previously alluded to, the primary benefit of the ``white flux''
features is that they can be calculated for every source in PS1 thus allowing
each to be compared on common ground. Furthermore, the SNR for the ``white
flux'' features is greater than the SNR for the equivalent feature in a
single filter. The downside of these features is that for some sources,
especially at the bright end, color information is lost. While a blue source
and red source with identical \texttt{whitePSFFlux} values are intrinsically
very different, the ``white flux'' features obscure that information for the
classifier. Ultimately, we tested models with and without the ``white flux''
features and found that they are statistically equivalent when tested with
the \textit{HST} training set.

The direct use of color information as model features would require reddening
corrections for all PS1 sources. Not only is this a daunting task, but
accurate corrections would require a priori knowledge as to which sources are
Galactic and which are extragalactic (e.g., \citealt{Green15}). The PS1
catalog is being developed precisely to answer this question. Furthermore,
the pencil beam sample from the \textit{HST} training set traces a narrow
range of dust columns, so the application of a model including color
information without reddening corrections would lead to biased
classifications, particularly in regions of high reddening (e.g., the
Galactic plane). We conclude that the benefits of the ``white flux''
features, which eliminate the need for reddening corrections, outweigh any
losses from the exclusion of color information.

\begin{figure*}[htb]
 \centering
  \includegraphics[width=5.75in
  % , bb = 139 113 862 1163
  ]{./Figures/whiteFeatures.pdf}
  \caption{
  The primary square panels show KDEs of the PDF for each of the ``white
  flux'' features as a function of \texttt{whiteKronMag}
  ($=-2.5\log_{10}[\mathtt{whiteKronFlux}/3631]$) for all sources in the
  \textit{HST} training set. Stars are shown via the red-purple contours,
  while galaxies are shown via blue-green contours. The shown contour levels
  extend from 0.9 to 0.1 in 0.1 intervals. To the right of each primary panel
  is a marginalized 1D KDE of the PDF for the individual features, where the
  amplitudes of the KDEs have been normalized by the relative number of stars
  and galaxies. The clear overlap between faint stars and galaxies suggests
  that a machine learning model may provide significant improvement over the
  PS1 and simple models.
  \yutaro{Should we add star/galaxy legend to each of these panels?}}
  %
  \label{fig:features}
\end{figure*}

The distribution of ``white flux'' features for stars and galaxies in the
\textit{HST} training set is shown in Figure~\ref{fig:features}
(\texttt{whitePSFKronDist} is shown in Figure~\ref{fig:psfkrondist}). As
might be expected, it is clear from Figure~\ref{fig:features} that stars and
galaxies are easily separated at the bright end ($\lesssim 20$\,mag), but
there is significant overlap in the featurespace between the two populations
at the faint end ($\sim$23\,mag). Machine learning algorithms are capable of
capturing non-linear behavior in multidimentional data sets, which will
prove especially useful for the sources under consideration in the PS1 data
set.

\section{Model Construction}
\subsection{The PS1 Baseline Model}\label{sec:ps1_model}

To establish a baseline for the performance of our star-galaxy separation
models we adopt the classification criteria in the PS1 documentation, namely
sources with 
%
$$ \mathtt{iPSFMag} - \mathtt{iKronMag} > 0.05\;\mathrm{mag},$$
%
are classified as
galaxies.\footnote{\url{https://outerspace.stsci.edu/display/PANSTARRS/How+to+
separate+stars+and+galaxies}} The documentation notes that this
classification can be performed using photometry from any of the
\textit{MeanObject}, \textit{ForcedMeanObject}, or \textit{StackedObjectThin}
tables. The PS1 documentation further notes that this basic cut does not
perform well for sources with $i \gtrsim 21\,\mathrm{mag}$, which constitutes
the majority of sources detected by PS1, and motivates us to develop
alternative models. We use the performance of the $\mathtt{iPSFMag} -
\mathtt{iKronMag} > 0.05\;\mathrm{mag}$ model (hereafter, the PS1 model) as a
baseline to compare to the models discussed below.

\subsection{Simple Model}\label{sec:simple_model}

While our ultimate goal is to build a machine learning model to separate
stars and galaxies (\S\ref{sec:rf_model}), we first construct a
straightforward model. This model is inspired by the SDSS \texttt{photo}
pipeline \citep{Lupton01}, and combines the flux in each of the 5 PS1 filters
to improve the SNR relative to any individual band. In addition to being easy
to interpret, this model (hereafter, the simple model), which utilizes the
difference between the PSF flux and the Kron-aperture flux for
classification, serves as an additional baseline to test the need for a more
complicated machine learning model.

It stands to reason that a model built on all five PS1 filters should outperform a model constructed from a single filter. To that end, we examine the \texttt{whitePSFKronRatio} (equivalent to $\mathtt{whitePSFMag} - \mathtt{whiteKronMag}$) to discriminate between stars and galaxies. The upper left panel of Figure~\ref{fig:features} shows that sources with $\mathtt{whitePSFKronRatio} \gtrsim 1$ are very likely to be stars. A single hard cut on \texttt{whitePSFKronRatio}, similar to the SDSS \texttt{photo} pipeline or the PS1 model, removes any sense of confidence in the corresponding classification. For example, a source with $\mathtt{whitePSFKronRatio} = 1.1$ and $\mathtt{whiteKronMag} \approx 17\,\mathrm{mag}$ is far more likely to be a star than a source with the same \texttt{whitePSFKronRatio} value but $\mathtt{whiteKronMag} \approx 23\,\mathrm{mag}$ (see Figure~\ref{fig:features}).

To address this issue of classification confidence, we measure the
orthogonal distance from a line ($\mathtt{whitePSFFlux} = a\times
\mathtt{whiteKronFlux}$) for all sources in the
$\mathtt{whitePSFFlux}$--$\mathtt{whiteKronFlux}$ plane to define the simple model:
%
\begin{multline}
 \mathtt{whitePSFKronDist}(a) = \\
 \frac{\mathtt{whitePSFFlux} - a\times\mathtt{whiteKronFlux}}{ \sqrt{1 + a^2}},
 \label{eqn:psfkrondist}
\end{multline}
%
where $a$ is the slope of the line. For $a \approx 1$, which is similar to a
hard cut with $\mathtt{whitePSFKronRatio} = a$, bright stars will have
large, positive values of \texttt{whitePSFKronDist}, while bright galaxies
will have large, negative values of \texttt{whitePSFKronDist}.
Simultaneously, faint sources, which are more difficult to classify, will
have small values of \texttt{whitePSFKronDist}. The simple model allows us
to produce a rank ordered classification, which in turn allows us to
evaluate the optimal classification threshold for the separation of stars
and galaxies (see \S\ref{sec:comp_hst}).

The optimal value for $a$ is determined via $k$-fold cross validation (CV).
We adopt identical procedures to optimize both the simple model and the
machine learning model (see \S\ref{sec:rf_model}). We employ the use of an
inner and outter CV loop, both of which have $k = 10$ folds. In the outter
CV loop, the training set is split into 10 separate partitions, each
iteratively withheld from the training. For each partition in the outter CV
loop, an inner 10-fold CV is applied to the remaining $\sim$90\% of the
training set to determine the optimal model parameters. Predictions on the
sources withheld in the outter loop are made with the optimal model from the
inner loop to provide model predictions for every source in the training
set. We adopt final, optimal tuning parameters from the mean of the values
determined in the inner CV.

For the simple model, we employ a grid search over $a$ in the inner CV loops
to maximize the FoM and thereby determine the optimal value of $a$.
Initially, a wide grid from 0 to 2 was searched, followed by a fine grid
search over $a$ from 0.75 to 1.25 with step size = 0.0025. The average
optimal $a$ from the inner loops, and hence final model value, is 0.91375,
with sample standard deviation $\sim$0.01. From this procedure, we find that
for the simple model the $\mathrm{FoM} = 0.62 \pm 0.02$, where the
uncertainty is estimated from the scatter in the outter CV
results.\footnote{We find that PS1 flux measurements from the
\textit{StackObjectThin} table produce a higher FoM for the simple model
than flux measurements from the \textit{MeanObject} and
\textit{ForcedMeanObject} tables. Thus, we adopt \textit{StackObjectThin}
fluxes for both the simple model and the machine learning model, as noted in
\S\ref{sec:model_data}.}


\begin{figure}[t]
 \centering
  \includegraphics[width=3.55in]{./Figures/whitePSFKronDist.pdf}
  %
  \caption{ The distribution of $\mathtt{whitePSFKronDist}$ values for
  \textit{HST} training set stars and galaxies as a function of
  \texttt{whiteKronMag}. The colors and contours are the same as
  Figure~\ref{fig:features}. The horizontal dashed line shows the optimal
  threshold ($\mathtt{whitePSFKronDist} \ge 9.2 \times 10^{-7}$) for
  star--galaxy classification. The upper-right inset shows a zoom-out
  highlighting the stark difference between stars and galaxies at the bright
  end. }
  %
  \label{fig:psfkrondist}
\end{figure}


The distribution of $\mathtt{whitePSFKronDist}(a=0.91375)$ is shown for \textit{HST} training set stars and galaxies in Figure~\ref{fig:psfkrondist}. $\mathtt{whitePSFKronDist}$ provides an excellent discriminant between bright ($\lesssim 20\,\mathrm{mag}$) stars and galaxies. We further find that adopting a stellar classification threshold of $\mathtt{whitePSFKronDist} \ge 9.2 \times 10^{-7}$ produces a classification accuracy of $\sim$91\%.

\subsection{Random Forest Model}\label{sec:rf_model}

\subsubsection{The Random Forest Algorithm}\label{sec:rf_alg}
\NC{For constructing the machine learning model (hereafter ML model) 
to capture non-linear behavior in multidimensional data sets, 
we use random forest (RF) algorithm in this study.  
This algorithm is based on decision tree models \citep{Quinlan93} 
and bagging, 
wherein bootstrap samples of the training set are utilized to construct 
each of the $N_{\mathrm{tree}}$ total trees in the forest,
for classification problems \citep{Breiman96, Breiman01}. 
Each tree in the forest is trained by only a random subset of $m_{\mathrm{try}}$ 
features selected from the full feature set, 
and the use of bagging and random selected $m_{\mathrm{try}}$ features 
allows the final model to provide low-bias and low-variance predictions, 
where the number of terminal node (the depth) of individual tree is limited to be larger than \texttt{nodesize}. 

The final predictions for a new unknown source are determined by voting or averaging the predictions 
from each of the individual trees. 
Because of its insensitivity to noisy or meaningless features and also outlier values in them, 
RF algorithms have recently applied for astronomical data sets frequently, 
such as light curve classification ({\it e.g., } \citealt{Richards12a, Huppenkothen17}), 
real and bogus discrimination of difference image ({\it e.g., }  \citealt{Brink13, Wright15}), 
and star and galaxy separation ({\it e.g., } \citealt{Vasconcellos11, Miller17}). 
We utilize the \texttt{Python scikit-learn} implementation of the RF algorithm \citep{Pedregosa12} in this study. 

\subsubsection{Feature Selection}
As we mentioned in \S\ref{sec:model_features}, 11 image features are utilized for training the machine learning classifier: 
\texttt{whiteExtNSigma}, \texttt{whiteKronRad}, \texttt{whitepsfChiSq}, \texttt{whitepsfLikelihood}, 
\texttt{whitemomentYY}, \texttt{whitemomentXY}, \texttt{whitemomentXX}, \texttt{whitemomentRH}, 
\texttt{whitePSFKronRatio}, \texttt{whitePSFApRatio} (Figure \ref{fig:features}), 
and \texttt{whitePSFKronDist} (Figure \ref{fig:psfkrondist}). 

While the ML model trained by RF algorithm 
would provide low-variance and low-biased predictions 
in the presence of strongly correlated features\footnote{Some features have a relatively strong correlation coefficient: 
$\sim0.94$ between \texttt{whiteExtNSigma} and \texttt{whitepsfLikelihood}, 
$\sim0.69$ between \texttt{whiteMomentXX} and \texttt{whiteMomentYY}, and 
$\sim0.50$ between \texttt{whitePSFApRatio} and \texttt{whitePSFKronRatio}. }
 or weak/uninformative features ({\it e.g.,} \citealt{Richards12a}), 
it is worthful to investigate whether the model performance is improved by removing some features. 
We employ two methods to test the full feature set: 
(1) forward feature selection ({\it e.g.,} \citealt{Richards12a, Miller17}) and 
(2) backward feature selection ({\it e.g.,} \citealt{Brink13}). 
In the forward feature selection, 
we construct a series of ML models whereby we iteratively add one feature 
at a time to each successive model starting with the most-important-RF feature 
and ending with the least-important-RF feature 
based on the ranking of \texttt{importance} provided by the RF methods, 
that reflects the contribution of an individual feature to the final decision in RF models \citep{Breiman01, Breiman02}. 
On the other hand, in the backward feature selection, 
we remove a feature that provides no
useful information or hurt the classification performance 
successively from the RF model trained with the full set of features. 
In both cases, we found that any removal of features does not improve the performance of the ML model 
in terms of FoM\footnote{Figure of merit; the true positive ratio at the false positive ratio equal to 0.5\% in this study. } 
significantly. 
We therefore decide to use all of 11 features to train the final ML model. 

\subsubsection{Optimizing the Model Tuning Parameters}
The RF algorithm has the two most important hyperparameters, $N_{\mathrm{tree}}$ and $m_{\mathrm{try}}$, 
and an additional parameter \texttt{nodesize} (see \S\ref{sec:rf_alg}), 
for controlling the smoothness of the model projection in multidimensional feature space. 
To construct the optimal ML model, we perform a grid search over the RF tuning parameters 
$N_{\mathrm{tree}}$, $m_{\mathrm{try}}$ and \texttt{nodesize}. 
Averaging over 10-fold cross-validated FoM, 
we found that the performance of the ML model is maximized for the model 
($N_{\mathrm{tree}} = 400$, $m_{\mathrm{try}} = 4$, $\mathtt{nodesize} = 2$). 
We note that the final ML model prediction is not sensitive to change in these parameters: 
most of the FoM of ML model with different parameters is within the standard deviation 
of CV FoM derived by the optimal ML model. 
}
\section{Classification Performance}

\subsection{PS1, Simple, ML model Comparison}\label{sec:comp_hst}
\NC{To test the classification performance of the ML model, 
we first assess the ROC curve and the prediction accuracy 
of the ML model by comparing that of PS1 model, and the simple model, 
via a 10-fold CV run on the training set ({\it i.e.,} PS1 sources cross-matched against the HST COSMOS catalog) 
by comparing predictions of each model with HST classifications. 
%%% fig:cvroc_hst %%%
\begin{figure}[t]
 \centering
  \includegraphics[width=3.35in, bb = 0 0 576 360]{./Figures/CV_ROC_HST.pdf}
  \caption{
  ROC curves comparing the relative performance of the PS1, the simple, and the ML model. 
  We use PS1 sources cross-matched against the HST COSMOS catalog with 
  $\mathtt{iPSFMag} - \mathtt{iKronMag} \neq \mathrm{NaN}$ 
  so that any source in the dataset has a classification from all each model 
  for a fair comparison. 
  The solid orange, blue, and black line show the ROC curve 
  for the PS1 model, the simple model, and ML model, respectively. 
  Color-shadowed regions represent the standard deviation of each TPRs derived by 10-fold CV. 
  The ROC curves around FPR = 0.005 (grey solid line) are shown in the inset panel 
  (the ROC curve for the PS1 model is located at substantially below of the TPR range shown in the inset panel). 
  }
  %
  \label{fig:cvroc_hst}
\end{figure}
%%%%%%%%%%%%%

Figure \ref{fig:cvroc_hst} shows the CV ROC curve of each models, 
and reveals the ML model is apparently outperformed to the other models. 
The overall ROC curve of the simple model, the new baseline for the performance of the star and galaxy separation, 
superiors to that of the PS1 model. 
The higher SNR of the difference between 
the \texttt{PSFFlux} and the \texttt{KronFlux} for each source 
in the simple model actually makes the performance of the classifier better, 
but the way to scoring to each object in this model, namely employing the distance from the threshold line, 
plays the most important role for this improvement, 
especially at the low FPR end (detail about the simple model, please see \S\ref{sec:simple_model}). 
In the simple model, a source difficult to judge whether it is star or galaxy ({\it i.e.,} a source at the faint end) 
has a score close to 0, 
while the source which can be distinguished clearly from a point source on the image 
has a large negative score (and vise versa for a point source). 
As most stars do not have such large negative values, 
the lower FPR and the higher TPR is obtained at a large minus threshold for the star-galaxy classification. 
In the PS1 model, on the other hand, the classification is decided by $\mathtt{iPSFMag} - \mathtt{iKronMag}$, 
has an (essentially) identical score $\sim$0 for all stars independently of its distinguishability. 
The difference of the scoring method makes substantial improvement in the performance of the PS1 model 
from that of the simple model at low FPR end. 

Since the ML model is trained with the 11 features 
consisting \texttt{whitepsfKronDist} and \texttt{whitepsfKronRatio}, 
which is the fundamental information for the classification in the  simple model and the PS1 model, respectively, 
the TPR of the ML model is higher than that of baseline models in whole FPR value. 
The ROC AUC is 0.973, 0.937, and 0.851, 
and the FoM is 0.715, 0.658, and 0.007, 
for the PS1 model, the simple model, and the ML model, respectively; 
in the other words, the TPR at the FPR$=0.5\%$ of the ML model and the simple model 
is improved 70.8$\%$ and 65.1$\%$ from that of the PS1 model, respectively. 

In Figure \ref{fig:cvacc_hst}, we compare the accuracy 
of the PS1 model, the simple model, and the ML model
evaluated via the PS1-HST data set as a function of \texttt{whiteKronMag}. 
%%% fig:cvacc_hst %%%
\begin{figure}[t]
 \centering
  \includegraphics[width=3.35in, bb = 0 0 576 360]{./Figures/CV_Accuracy_HST.pdf}
  \caption{
  Predication accuracy of the PS1 model (orange filled circles), the simple model (blue filled circles), 
  and the ML model (black filled circles), as a function of \texttt{whiteKronMag} 
  for PS1 sources cross-matched against the HST COSMOS catalog. 
  Accuracies are shown in bin of width 0.5 mag, and the error bars 
  represents the range including 68\% of CV accuracies in each bin. 
  Additionally, a KDE of the PDF for stars and galaxies in the data set is shown in red and green, respectively. 
  The PDF of stars and galaxies has been normalized by the ratio of the number of stars and galaxies 
  to the full number of sources in the data set, respectively. 
  The KDE of the PDF for all sources in the dataset is also shown in grey.
  }
  %
  \label{fig:cvacc_hst}
\end{figure}
%%%%%%%%%%%%%
In the PS1 model, prediction accuracy quickly decrease from $\mathtt{whiteKronMag} \sim $ 20 mag, 
to the level of random predictions (accuracy $\sim$ 0.5) for sources with $\mathtt{whiteKronMag} \gtrsim $ 23 mag. 
In the simple model, on the other hand, 
although is starting to decrease from $\mathtt{whiteKronMag} \sim $ 20 mag gradually to the faintest end, 
the accuracy is above 80\% even for sources fainter than $\mathtt{whiteKronMag} \sim $ 23.5 mag. 
This is mainly because of higher SNR in ``white feature'' of the difference 
between \texttt{Kron} flux measurement and \texttt{PSF} flux measurement for each source (see \S\ref{sec:model_features}), 
that differs to the case of the improvement of the ROC curve mentioned above. 

The performance of the ML model is the best among other baseline models in almost all brightness of a source in the dataset, 
but one notice to the similarity of the accuracy curve of the ML model and the simple model. 
This is because of the highest importance of the \texttt{whitepsfKronDist} 
among all of 11 features for the classification of the ML model. 
The overall CV accuracy of the ML model, the simple model, and the PS1 model is 
93.3\%, 91.6\%, and 78.4\%. 
As previously mentioned, the ML model provides superior predictions 
especially for faint sources, which will enable to us to best identify stars in ZTF survey imaging 
even outside the COSMOS field. 
Figure \ref{fig:cvacc_hst} also shows a KDE of the PSD of stars and galaxies in the PS1-HST data set 
as a function of \texttt{whiteKronMag}. 
The KDEs indicate that most sources brighter than $\mathtt{whiteKronmag} \lesssim 19$ is star, 
while the number of galaxies overwhelms that of stars from $\mathtt{whiteKronmag} \gtrsim 21$ to the faintest end. 
The KDE of PDF for stars and galaxies has a peak around $\mathtt{whiteKronMag} \sim 21.5$ and $\sim 22$, 
respectively. 
We note that such distribution should be low-biased for the PS1 sources 
since all of the sources are taken from imaging data sets. 

\subsection{ML Comparison with SDSS photo}
%%% fig:roc_sdss %%%
\begin{figure}[t]
 \centering
  \includegraphics[width=3.35in, bb = 0 0 576 360]{./Figures/ROC_curves.pdf}
  \caption{
  ROC curves comparing the relative performance 
  of the SDSS photo model (green solid line), the PS1 model (orange solid line), 
  the simple model (blue solid line), and the Ml model (black solid line) 
  for PS1 sources cross-matched against the SDSS spectroscopic catalog. 
  The SDSS photometric classifier is shown as a red star on the ROC curve of the SDSS photo model, 
  due to the binary nature of the SDSS photometric classification. 
  The inset panel shows ROC curves around the FPR = 0.005 (grey solid line). 
  }
  %
  \label{fig:roc_sdss}
\end{figure}
%%%%%%%%%%%%%
Next, we assess the performance of the ML model by comparing with SDSS photometric classification 
by using PS1-SDSS spectroscopic catalog. 
Figure \ref{fig:roc_sdss} shows the ROC curve for 
the SDSS photo, the PS1 model, the simple model, and the ML model, 
by comparing predictions with SDSS spectroscopic classifications, 
which are independent of the training data set; PS1-HST cross-matched catalog. 
For sources in PS1-SDSS catalog, broadly, 
the performance of classifications by each model is better than that for sources in PS1-HST catalog. 
This is simply because that the distribution of sources, especially galaxies, in PS1-SDSS catalog 
are biased toward to brighter side comparing with of PS1-HST catalog. 
The selection bias of the SDSS spectroscopic survey 
toward observing luminous red galaxies (LRGs; {\it e.g.,} see \citealt{Eisenstein01}) 
results in the KDE of the PDF of galaxies having two peaks 
at $\mathtt{whiteKronMag} \sim 17$ and $\sim 20$ 
(see \S\ref{sec:sdss} and the left panel in Figure \ref{fig:acc_sdss}). 
As we alluded to in \S\ref{sec:comp_hst}, 
the distribution of stars and galaxies in the real universe (except the galactic plane) 
should be similar to that shown in Figure \ref{fig:cvacc_hst}; 
the peak of the distribution for stars and galaxies is around $\mathtt{whiteKronMag} \sim 22$ 
and the number of stars and of galaxies is dominant at the bright end and the faint end, 
respectively \citep{Chambers16}. 
Although the data set has the selection bias as mentioned above 
and thus the distribution of stars and galaxies as a function of brightness is totally different to that of the training set, 
the ROC curve of ML model is superior to the other models in terms of the FoM and also the ROC AUC; 
the FoM for the SDSS model, the PS1 model, the simple model, and the ML model is 
0.777, 0.290, 0.798, and 0.843, respectively, 
and the ROC AUC score for each model is 
0.987, 0.984, 0.985, and 0.987, respectively. 

%%% fig:acc_sdss %%%
\begin{figure*}[t]
 \centering
  \includegraphics[width=6.5in, bb = 0 0 900 360]{./Figures/Accuracy_SDSS_ML_model.pdf}
  \caption{
  Prediction accuracy of the SDSS photo model and the ML model 
  as a function of \texttt{whiteKronmag} for PS1 sources cross-matched against the SDSS spectroscopic catalog. 
  In the left panel, the green filled square and the green filled triangle 
  show the prediction accuracy of the SDSS photo model for galaxies and stars, respectively, 
  and the black filled square and the black filled triangle show that of the ML model for galaxies and stars, respectively. 
  Accuracies are calculated in each 0.5 mag bin. 
  The KDE of the normalized PDF of stars and galaxies 
  in the PS1-SDSS cross-matched catalog is also shown in red and green, respectively (same manner as Fig. \ref{fig:cvacc_hst}). 
  In the right panel, the overall accuracy of the SDSS photo model and the ML model 
  as a function of \texttt{whiteKronMag} is shown by filled green circle and filled black circle, respectively. 
  The accuracy in each bin is calculated for stars and galaxies picked up 
  from PS1-SDSS cross-matched catalog 
  so that the ratio the number of stars and galaxies in each bin is 
  same with that in the PS1-HST cross-matched catalog. 
  The KDE of PDF of stars and galaxies in PS1-HST cross-matched catalog is shown in red and green, respectively. 
  } 
  %
  \label{fig:acc_sdss}
\end{figure*}
%%%%%%%%%%%%%
In the left panel of Figure \ref{fig:roc_sdss}, we show the prediction accuracy of the SDSS photo model 
and the ML model for galaxies and stars separately. 
One can see that an unusual systematic whereby a large fraction of stars with $\mathtt{whiteKronMag} \sim 20$ 
were erroneously classified as galaxies by both of models. 
The reason of it is discussed by \cite{Miller17}; 
red stars blended with fainter sources would be classified to be galaxies. 
Interestingly, for the SDSS photo model, the accuracy for galaxies is rapidly decreasing from \texttt{whiteKronMag}, 
while that for stars stays above $\sim 0.9$. 
It means the SDSS photo model is optimized to separate stars and galaxies in the SDSS spectroscopic catalog, 
namely, the model classifies most of faint sources as stars 
since the number of stars overwhelms that of galaxies from $\sim 21$ mag to the faint end in this catalog. 

For evaluating the performance of the SDSS photo model and the ML model 
for the star/galaxy population similar to the real universe, 
we calculate the prediction accuracy of each model in a different way; 
we pick up sources from PS1-SDSS catalog 
so that the ratio of the number of stars and to the number of galaxies 
is same as that in PS1-HST catalog, and then calculate the prediction accuracy of each model in each 0.5 mag bin. 
The result is shown in the right panel of Figure \ref{fig:acc_sdss}. 
The prediction accuracies shows that the performance of each model is similar 
down to $\mathtt{whiteKronMag} \sim20.5$, 
while the performance of the SDSS photo model quickly degrades for fainter sources. 
This is to be expected based on the poor performance for faint galaxies of the SDSS photo model; 
the PS1-HST catalog (and also the real universe) contains much larger number of faint galaxies than faint stars. 
The final ML model, which is optimized to classify stars and galaxies following this population, 
will provide the most accurate classification for sources in high-latitude sky. 
} 
\section{Discussion}

\section{The PS1 Catalog Deployed: Integration in ZTF}

\todo{provide a description for how the catalog is used by ZTF in real-time ops}

The Zwicky Transient Facility (ZTF; 
\citealt{Kulkarni12, Bellm14, Smith14, Dekany16, Bellm17})\footnote{\url{http://www.ztf.caltech.edu/}} 
was started and had the first light at Palomar Observatory in 2017, 
as the next generation Palomar time-domain survey 
subsequent to the Palomar Transient Facility (PTF; \citealt{Rau09, Law09}) 
and the intermediate Palomar Transient Facility (iPTF; \citealt{Kulkarni13}). 
A dedicated survey of the variable sky by ZTF is ongoing with the new camera 
utilizing the entire focal plane on 47 deg$^2$ of the Palomar 48-inch Samuel Oschin Schmidt telescope. 
ZTF is scanning more than 3,750 deg$^2$ an hour to depth $R < 20.4$ mag ($5\sigma$ detection), 
and will produce a photometric variability catalog with nearly 300 observations each year. 
A primary motivation for ZTF is the search for fast transients 
including ``kilonovae'' 
associated with gravitational waves, 
the result of binary neutron star mergers 
(GW170817; {\it e.g.,} \citealt{Abbott17, Cowperthwaite17, Lipunov17, Kasliwal17, Utsumi17, Tanaka17}). 

ZTF surveys the sky at a rate that is $\sim15$ times faster than PTF/iPTF. 
The increase in the amount of astronomical data with a rapidly accelerating pace 
results in the necessity of automated classification and filtering by machines to investigate objects 
that we are potentially interested in. 
To identify fast-transient candidates, including gravitational wave (GW) counterparts especially, 
astronomers have contended with significant foreground contamination in the form of stellar flares 
and/or orbital modulation ({\it e.g.,} \citealt{Kulkarni06, Berger12, Kasliwal16}). 
The systematic removal of faint stars from extragalactic candidate lists 
enables us to follow-up such exotic sources efficiently under the limitation of time, instrumental, and human resources. 
The follow-up efficiency will be required more strongly from the beginning of the third observing run of LIGO/VIRGO 
collaborating with KAGRA in 2019. 


\section{Conclusions}

%%%%%%%%
\begin{table*}
\begin{center}
\caption{The true positive ratio and the threshold 
corresponding to the false positive ratio = 0.005, 0.01, 0.02, 0.05, and 0.1. }
\label{tbl:fpr}
\begin{tabular}{lcc|lccccc}
\hline\hline
                 Source               & Num. & Acc. & FPR & 0.005 & 0.01 & 0.02 & 0.05 & 0.1 \\ \hline
\multirow{2}{*}{All sources} & \multirow{2}{*}{47,093} & \multirow{2}{*}{93.1\%} & 
                                              TPR  & $0.697 \pm 0.008$ &  $0.742 \pm 0.005$ & $0.786 \pm 0.003$ & $0.852 \pm 0.003$ & $0.899 \pm 0.003$  \\
\multicolumn{1}{l}{}                             & & & Threshold & $0.76 \pm 0.05$ &  $0.65 \pm 0.04$ & $0.53 \pm 0.02$ & $0.36 \pm 0.01$ & $0.24 \pm 0.01$  \\ \hline
\multirow{2}{*}{$\mathtt{rKornMag} < 21$} & \multirow{2}{*}{13,766} & \multirow{2}{*}{97.8\%} & 
                                              TPR  & $0.861 \pm 0.062$ &  $0.953 \pm 0.024$ & $0.986 \pm 0.002$ & $0.993 \pm 0.001$ & $0.996 \pm 0.001$ \\
                                                & & & Threshold & $0.82 \pm 0.17$ &  $0.70 \pm 0.18$ & $0.40 \pm 0.10$ & $0.16 \pm 0.06$ & $0.07 \pm 0.03$   \\ \hline
\multirow{2}{*}{$\mathtt{rKornMag} < 20$}  & \multirow{2}{*}{6,992}& \multirow{2}{*}{98.8\%} & 
                                              TPR  & $0.841 \pm 0.075$ &  $0.958 \pm 0.028$ & $0.997 \pm 0.001$ & $0.998 \pm 0.001$ & $0.999 \pm 0.001$  \\
                                                 & &  & Threshold & $0.90 \pm 0.18$ &  $0.81 \pm 0.24$ & $0.77 \pm 0.26$ & $0.13 \pm 0.08$ & $0.06 \pm 0.04$ \\ \hline
\end{tabular}
\end{center}
\end{table*}
%%%%%%%%

The performance of the ML model is summarized in Table \ref{tbl:fpr}

\acknowledgements

\begin{itemize}
    \item Brian Bue (possibly also Umaa, check emails)
    \item PS1 casjobs (Bernie in particular)
\end{itemize}

AAM is funded by the Large Synoptic Survey Telescope Corporation in support of
the Data Science Fellowship Program. 
Y.T. is funded by JSPS KAKENHI Grant Numbers JP16J05742. 

\facility{PS1}

\software{\texttt{astropy} \citep{Astropy-Collaboration13}, 
          \texttt{scipy} \citep{Jones01}, 
          \texttt{matplotlib} \citep{Hunter07},
          \texttt{pandas} \citep{McKinney10}}


\appendix


\bibliographystyle{aasjournal}
\bibliography{star_gal}

\end{document}